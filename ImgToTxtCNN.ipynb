# Image Captioning Script for Google Colab
# Prerequisites
!pip install tensorflow numpy pillow

import tensorflow as tf
import numpy as np
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

class ImageCaptioner:
    def __init__(self):
        """
        Initialize the image captioning model with pre-trained components
        """
        # Load pre-trained image feature extraction model
        self.image_model = InceptionV3(weights='imagenet', include_top=True)
        
        # Simple caption generation components
        self.max_length = 34
        self.vocab_size = 5000
        
        # Placeholder for tokenizer and model (would be trained in a full implementation)
        self.tokenizer = Tokenizer(num_words=self.vocab_size, oov_token='<UNK>')
        
    def extract_features(self, image_path):
        """
        Extract features from an input image
        
        :param image_path: Path to the image file
        :return: Extracted image features
        """
        # Load and preprocess the image
        image = load_img(image_path, target_size=(299, 299))
        image = img_to_array(image)
        image = np.expand_dims(image, axis=0)
        image = preprocess_input(image)
        
        # Extract features using InceptionV3
        features = self.image_model.predict(image)
        
        return features
    
    def generate_basic_caption(self, image_path):
        """
        Generate a basic caption using pre-trained image classification
        
        :param image_path: Path to the image file
        :return: Generated caption
        """
        try:
            # Extract features
            features = self.extract_features(image_path)
            
            # Use InceptionV3's built-in classification as a simple captioning method
            predictions = decode_predictions(features, top=3)[0]
            
            # Construct a simple caption
            caption_parts = []
            for (number, label, score) in predictions:
                if score > 0.1:  # Only include predictions with confidence > 10%
                    caption_parts.append(f"a {label}")
            
            # Create final caption
            full_caption = " and ".join(caption_parts)
            
            print("Generated Caption:", full_caption)
            return full_caption
        
        except Exception as e:
            print(f"Error generating caption: {e}")
            return None

def main():
    # Option 1: Upload images using Colab file upload
    from google.colab import files
    
    print("Please upload an image:")
    uploaded = files.upload()
    
    if uploaded:
        # Get the filename of the first uploaded image
        image_path = list(uploaded.keys())[0]
        
        # Create captioner and generate caption
        captioner = ImageCaptioner()
        captioner.generate_basic_caption(image_path)
    else:
        print("No image was uploaded. Please try again.")

# Run the main function
main()